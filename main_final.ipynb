{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c350f55-e47a-4324-af66-b1e23554a01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "GPU Device Name:  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check available devices\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Device Name: \", tf.test.gpu_device_name())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094ee82-6841-4d79-89d1-88dfdaaca775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# Clear the session to free up memory\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fa42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_strict_conv_algorithm_picker=false\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b7fc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c92c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Using GPU: {gpu}\")\n",
    "\n",
    "# Debugging logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a64ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Concatenate\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load NIfTI images\n",
    "def load_nii(file_path):\n",
    "    img = nib.load(file_path)\n",
    "    data = img.get_fdata()\n",
    "    return np.array(data, dtype=np.float32)\n",
    "\n",
    "# Resize images to a consistent shape\n",
    "def resize_image(image, target_shape=(240, 240, 240)):\n",
    "    return resize(image, target_shape, mode='reflect', anti_aliasing=True)\n",
    "\n",
    "# Normalize image to range [0, 1]\n",
    "def normalize(image):\n",
    "    return (image - np.min(image)) / (np.max(image) - np.min(image))\n",
    "\n",
    "# Apply brain mask to image\n",
    "def apply_mask(image, mask):\n",
    "    return image * mask\n",
    "\n",
    "# Load dataset and preprocess\n",
    "def load_dataset_with_manual_masks(base_path, mode='Training'):\n",
    "    data = []\n",
    "    mode_path = os.path.join(base_path, mode)\n",
    "    centers = [os.path.join(mode_path, center) for center in os.listdir(mode_path) if os.path.isdir(os.path.join(mode_path, center))]\n",
    "\n",
    "    for center in centers:\n",
    "        patients = [os.path.join(center, patient) for patient in os.listdir(center) if os.path.isdir(os.path.join(center, patient))]\n",
    "        for patient in patients:\n",
    "            preprocessed_path = os.path.join(patient, 'Preprocessed_Data')\n",
    "            t1_path = os.path.join(preprocessed_path, 'T1_preprocessed.nii.gz')\n",
    "            t1ce_path = os.path.join(preprocessed_path, 'GADO_preprocessed.nii.gz')\n",
    "            mask_path = os.path.join(patient, 'Masks', 'Brain_Mask.nii.gz')\n",
    "            manual_masks = glob(os.path.join(patient, 'Masks', 'ManualSegmentation_*.nii.gz'))\n",
    "\n",
    "            if os.path.exists(t1_path) and os.path.exists(t1ce_path) and os.path.exists(mask_path) and len(manual_masks) > 0:\n",
    "                data.append({\n",
    "                    't1': t1_path,\n",
    "                    't1ce': t1ce_path,\n",
    "                    'mask': mask_path,\n",
    "                    'manual_masks': manual_masks\n",
    "                })\n",
    "    return data\n",
    "\n",
    "# Preprocessing function for a given patient data\n",
    "def preprocess_with_manual_masks(t1_path, t1ce_path, mask_path, manual_mask_paths):\n",
    "    t1 = normalize(load_nii(t1_path))\n",
    "    t1ce = normalize(load_nii(t1ce_path))\n",
    "    brain_mask = load_nii(mask_path)\n",
    "    manual_masks = [load_nii(m) for m in manual_mask_paths]\n",
    "    combined_mask = np.mean(manual_masks, axis=0)\n",
    "    combined_mask = (combined_mask > 0.5).astype(np.float32)\n",
    "\n",
    "    # Apply brain mask\n",
    "    t1 = apply_mask(t1, brain_mask)\n",
    "    t1ce = apply_mask(t1ce, brain_mask)\n",
    "    combined_mask = apply_mask(combined_mask, brain_mask)\n",
    "\n",
    "    # Resize images to consistent shape\n",
    "    t1 = resize_image(t1)\n",
    "    t1ce = resize_image(t1ce)\n",
    "    combined_mask = resize_image(combined_mask)\n",
    "\n",
    "    return t1, t1ce, combined_mask\n",
    "\n",
    "# Retina U-Net model\n",
    "def retina_unet_with_manual_masks(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    c1 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "\n",
    "    c2 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "\n",
    "    c3 = Conv3D(256, (3, 3, 3), activation='relu', padding='same')(p2)\n",
    "\n",
    "    u1 = UpSampling3D((2, 2, 2))(c3)\n",
    "    u1 = Concatenate()([u1, c2])\n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(u1)\n",
    "\n",
    "    u2 = UpSampling3D((2, 2, 2))(c4)\n",
    "    u2 = Concatenate()([u2, c1])\n",
    "    c5 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(u2)\n",
    "\n",
    "    outputs = Conv3D(1, (1, 1, 1), activation='sigmoid')(c5)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Synthesis Module\n",
    "def synthesis_module(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    c1 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv3D(64, (3, 3, 3), activation='relu', padding='same')(c1)\n",
    "\n",
    "    c2 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c1)\n",
    "    c2 = Conv3D(128, (3, 3, 3), activation='relu', padding='same')(c2)\n",
    "\n",
    "    outputs = Conv3D(1, (1, 1, 1), activation='linear')(c2)\n",
    "    return tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "dataset_path = \"dataset\"\n",
    "train_data = load_dataset_with_manual_masks(dataset_path, mode='Training')\n",
    "test_data = load_dataset_with_manual_masks(dataset_path, mode='Testing')\n",
    "\n",
    "train_images = [preprocess_with_manual_masks(d['t1'], d['t1ce'], d['mask'], d['manual_masks']) for d in train_data]\n",
    "test_images = [preprocess_with_manual_masks(d['t1'], d['t1ce'], d['mask'], d['manual_masks']) for d in test_data]\n",
    "\n",
    "x_train = np.expand_dims(np.array([img[0] for img in train_images]), axis=-1)\n",
    "y_train = np.expand_dims(np.array([img[2] for img in train_images]), axis=-1)\n",
    "\n",
    "# TensorBoard and Checkpoint Callbacks\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, profile_batch=2)\n",
    "\n",
    "checkpoint_dir = \"checkpoints/retina_unet/\"\n",
    "retina_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, \"cp-{epoch:04d}.weights.h5\"),\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Retina U-Net training\n",
    "retina_model = retina_unet_with_manual_masks(input_shape=(240, 240, 240, 1))\n",
    "retina_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "if latest_checkpoint:\n",
    "    retina_model.load_weights(latest_checkpoint)\n",
    "    print(f\"Loaded Retina U-Net checkpoint from {latest_checkpoint}\")\n",
    "\n",
    "retina_model.fit(\n",
    "    x_train, y_train, \n",
    "    epochs=50, \n",
    "    batch_size=2, \n",
    "    callbacks=[tensorboard_callback, retina_checkpoint_callback]\n",
    ")\n",
    "\n",
    "semantic_features = retina_model.predict(x_train)\n",
    "combined_input = np.concatenate([x_train, semantic_features], axis=-1)\n",
    "\n",
    "# Synthesis Module\n",
    "synthesis_checkpoint_dir = \"checkpoints/synthesis_module/\"\n",
    "synthesis_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(synthesis_checkpoint_dir, \"cp-{epoch:04d}.ckpt\"),\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "synthesis_model = synthesis_module(input_shape=(240, 240, 240, 2))\n",
    "synthesis_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss='mse')\n",
    "\n",
    "latest_synthesis_checkpoint = tf.train.latest_checkpoint(synthesis_checkpoint_dir)\n",
    "if latest_synthesis_checkpoint:\n",
    "    synthesis_model.load_weights(latest_synthesis_checkpoint)\n",
    "    print(f\"Loaded Synthesis Module checkpoint from {latest_synthesis_checkpoint}\")\n",
    "\n",
    "synthesis_model.fit(\n",
    "    combined_input, x_train, \n",
    "    epochs=50, \n",
    "    batch_size=2, \n",
    "    callbacks=[tensorboard_callback, synthesis_checkpoint_callback]\n",
    ")\n",
    "\n",
    "# Evaluation on test data\n",
    "x_test = np.expand_dims(np.array([img[0] for img in test_images]), axis=-1)\n",
    "semantic_features_test = retina_model.predict(x_test)\n",
    "combined_input_test = np.concatenate([x_test, semantic_features_test], axis=-1)\n",
    "synthetic_t1ce = synthesis_model.predict(combined_input_test)\n",
    "\n",
    "# Visualize results\n",
    "for i in range(3):  # Visualize 3 test samples\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Original T1\")\n",
    "    plt.imshow(x_test[i, :, :, 120, 0], cmap='gray')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Synthetic T1CE\")\n",
    "    plt.imshow(synthetic_t1ce[i, :, :, 120, 0], cmap='gray')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Ground Truth T1CE\")\n",
    "    plt.imshow(test_images[i][1][:, :, 120], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3de7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfb0c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
